{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":477177,"sourceType":"datasetVersion","datasetId":216167}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tfx","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:43:10.534473Z","iopub.execute_input":"2025-02-25T02:43:10.534738Z","iopub.status.idle":"2025-02-25T02:46:47.184698Z","shell.execute_reply.started":"2025-02-25T02:43:10.534701Z","shell.execute_reply":"2025-02-25T02:46:47.183640Z"}},"outputs":[{"name":"stdout","text":"Collecting tfx\n  Downloading tfx-1.16.0-py3-none-any.whl.metadata (37 kB)\nCollecting ml-pipelines-sdk==1.16.0 (from tfx)\n  Downloading ml_pipelines_sdk-1.16.0-py3-none-any.whl.metadata (33 kB)\nRequirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.4.0)\nCollecting ml-metadata<1.17.0,>=1.16.0 (from tfx)\n  Downloading ml_metadata-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: packaging>=22 in /usr/local/lib/python3.10/dist-packages (from tfx) (24.2)\nRequirement already satisfied: portpicker<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.5.2)\nRequirement already satisfied: protobuf<5,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tfx) (3.20.3)\nRequirement already satisfied: docker<8,>=7 in /usr/local/lib/python3.10/dist-packages (from tfx) (7.1.0)\nCollecting google-apitools<1,>=0.5 (from tfx)\n  Downloading google_apitools-0.5.32-py3-none-any.whl.metadata (2.3 kB)\nCollecting google-api-python-client<2,>=1.8 (from tfx)\n  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: jinja2<4,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from tfx) (3.1.4)\nRequirement already satisfied: typing-extensions<5 in /usr/local/lib/python3.10/dist-packages (from tfx) (4.12.2)\nCollecting apache-beam<3,>=2.47 (from apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading apache_beam-2.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\nCollecting attrs<24,>=19.3.0 (from tfx)\n  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: click<9,>=7 in /usr/local/lib/python3.10/dist-packages (from tfx) (8.1.7)\nRequirement already satisfied: google-api-core<3 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.34.1)\nRequirement already satisfied: google-cloud-aiplatform<2,>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.74.0)\nRequirement already satisfied: google-cloud-bigquery<4,>=3 in /usr/local/lib/python3.10/dist-packages (from tfx) (3.25.0)\nRequirement already satisfied: grpcio<2,>=1.28.1 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.68.1)\nRequirement already satisfied: keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.4.7)\nCollecting kubernetes<27,>=10.0.1 (from tfx)\n  Downloading kubernetes-26.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: numpy<2,>=1.16 in /usr/local/lib/python3.10/dist-packages (from tfx) (1.26.4)\nCollecting pyarrow<11,>=10 (from tfx)\n  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nRequirement already satisfied: orjson!=3.10.7 in /usr/local/lib/python3.10/dist-packages (from tfx) (3.10.12)\nCollecting scipy<1.13 (from tfx)\n  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scikit-learn==1.5.1 (from tfx)\n  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: pyyaml<7,>=6 in /usr/local/lib/python3.10/dist-packages (from tfx) (6.0.2)\nCollecting tensorflow<2.17,>=2.16.0 (from tfx)\n  Downloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nCollecting tensorflow-hub<0.16,>=0.15.0 (from tfx)\n  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting tensorflow-data-validation<1.17.0,>=1.16.1 (from tfx)\n  Downloading tensorflow_data_validation-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\nCollecting tensorflow-model-analysis<0.48.0,>=0.47.0 (from tfx)\n  Downloading tensorflow_model_analysis-0.47.1-py3-none-any.whl.metadata (20 kB)\nCollecting tensorflow-serving-api<2.17,>=2.16 (from tfx)\n  Downloading tensorflow_serving_api-2.16.1-py2.py3-none-any.whl.metadata (1.8 kB)\nCollecting tensorflow-transform<1.17.0,>=1.16.0 (from tfx)\n  Downloading tensorflow_transform-1.16.0-py3-none-any.whl.metadata (13 kB)\nCollecting tfx-bsl<1.17.0,>=1.16.1 (from tfx)\n  Downloading tfx_bsl-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1->tfx) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1->tfx) (3.5.0)\nCollecting crcmod<2.0,>=1.7 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading crcmod-1.7.tar.gz (89 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading dill-0.3.1.1.tar.gz (151 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting cloudpickle~=2.2.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\nCollecting fastavro<2,>=0.23.6 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nCollecting fasteners<1.0,>=0.3 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\nCollecting grpcio<2,>=1.28.1 (from tfx)\n  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting hdfs<3.0.0,>=2.1.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading hdfs-2.7.3.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (0.22.0)\nRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (4.23.0)\nCollecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\nCollecting objsize<0.8.0,>=0.6.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (4.11.1)\nRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (1.25.0)\nCollecting pydot<2,>=1.2.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2.9.0.post0)\nRequirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2025.1)\nCollecting redis<6,>=5.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2024.11.6)\nRequirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2.32.3)\nRequirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2.4.0)\nCollecting zstandard<1,>=0.18.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting pyarrow-hotfix<1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: cachetools<6,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (5.5.0)\nCollecting google-api-core<3 (from tfx)\n  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting google-apitools<1,>=0.5 (from tfx)\n  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/173.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.0)\nRequirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (0.2.0)\nRequirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.20.2)\nRequirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.1)\nCollecting google-cloud-pubsublite<2,>=1.2.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading google_cloud_pubsublite-1.12.0-py2.py3-none-any.whl.metadata (5.8 kB)\nCollecting google-cloud-storage<3,>=2.18.2 (from apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\nCollecting google-cloud-bigquery-storage<3,>=2.6.3 (from apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading google_cloud_bigquery_storage-2.28.0-py2.py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: google-cloud-core<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.4.1)\nRequirement already satisfied: google-cloud-bigtable<3,>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.27.0)\nCollecting google-cloud-spanner<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading google_cloud_spanner-3.52.0-py2.py3-none-any.whl.metadata (10 kB)\nCollecting google-cloud-dlp<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading google_cloud_dlp-3.28.0-py2.py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: google-cloud-language<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.16.0)\nRequirement already satisfied: google-cloud-videointelligence<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (2.16.0)\nRequirement already satisfied: google-cloud-vision<4,>=2 in /usr/local/lib/python3.10/dist-packages (from apache-beam[gcp]<3,>=2.47->tfx) (3.10.0)\nCollecting google-cloud-recommendations-ai<0.11.0,>=0.1.0 (from apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading google_cloud_recommendations_ai-0.10.16-py2.py3-none-any.whl.metadata (5.4 kB)\nCollecting keyrings.google-artifactregistry-auth (from apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading keyrings.google_artifactregistry_auth-1.1.2-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=7->tfx) (2.3.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3->tfx) (1.66.0)\nRequirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client<2,>=1.8->tfx) (1.17.0)\nCollecting uritemplate<4dev,>=3.0.0 (from google-api-python-client<2,>=1.8->tfx)\n  Downloading uritemplate-3.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from google-apitools<1,>=0.5->tfx) (4.1.3)\nRequirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (1.14.0)\nRequirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (2.0.7)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (2.11.0a2)\nRequirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx) (0.16)\nRequirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4,>=3->tfx) (2.7.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4,>=2.7.3->tfx) (3.0.2)\nRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx) (3.5.0)\nRequirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx) (1.0.5)\nRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes<27,>=10.0.1->tfx) (2025.1.31)\nRequirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes<27,>=10.0.1->tfx) (75.1.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes<27,>=10.0.1->tfx) (1.8.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes<27,>=10.0.1->tfx) (1.3.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.16->tfx) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.16->tfx) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.16->tfx) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.16->tfx) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.16->tfx) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.16->tfx) (2.4.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker<2,>=1.3.1->tfx) (5.9.5)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.0->tfx) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.0->tfx) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.0->tfx) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.0->tfx) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.0->tfx) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.0->tfx) (18.1.1)\nCollecting ml-dtypes~=0.3.1 (from tensorflow<2.17,>=2.16.0->tfx)\n  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.0->tfx) (3.4.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.0->tfx) (2.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.0->tfx) (1.17.0)\nCollecting tensorboard<2.17,>=2.16 (from tensorflow<2.17,>=2.16.0->tfx)\n  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.0->tfx) (0.37.1)\nCollecting pandas<2,>=1.0 (from tensorflow-data-validation<1.17.0,>=1.16.1->tfx)\n  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting pyfarmhash<0.4,>=0.2.2 (from tensorflow-data-validation<1.17.0,>=1.16.1->tfx)\n  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.9/99.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting tensorflow-metadata<1.17,>=1.16.0 (from tensorflow-data-validation<1.17.0,>=1.16.1->tfx)\n  Downloading tensorflow_metadata-1.16.1-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: ipython<8,>=7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (7.34.0)\nCollecting ipywidgets<8,>=7 (from tensorflow-model-analysis<0.48.0,>=0.47.0->tfx)\n  Downloading ipywidgets-7.8.5-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (11.0.0)\nCollecting rouge-score<2,>=0.1.2 (from tensorflow-model-analysis<0.48.0,>=0.47.0->tfx)\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting sacrebleu<4,>=2.3 (from tensorflow-model-analysis<0.48.0,>=0.47.0->tfx)\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tensorflow-estimator>=2.10 (from tensorflow-model-analysis<0.48.0,>=0.47.0->tfx)\n  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: tf-keras>=2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-transform<1.17.0,>=1.16.0->tfx) (2.17.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.0->tfx) (0.45.1)\nRequirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2,>=1.6.2->tfx) (1.48.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx) (4.9)\nRequirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tfx) (0.13.1)\nRequirement already satisfied: opentelemetry-api>=1.27.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (1.29.0)\nRequirement already satisfied: opentelemetry-sdk>=1.27.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (1.29.0)\nRequirement already satisfied: overrides<8.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47->tfx) (7.7.0)\nRequirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx) (0.5.3)\nCollecting grpc-interceptor>=0.15.4 (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3,>=2.18.2->apache-beam[gcp]<3,>=2.47->tfx) (1.6.0)\nCollecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx)\n  Downloading docopt-0.6.2.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (3.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.7.5)\nRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (5.7.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (3.0.48)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (4.9.0)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.2.2)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.2.0)\nCollecting widgetsnbextension~=3.6.10 (from ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx)\n  Downloading widgetsnbextension-3.6.10-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting jupyterlab-widgets<3,>=1.0.0 (from ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx)\n  Downloading jupyterlab_widgets-1.1.11-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (0.22.3)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx) (0.13.1)\nRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->tfx) (0.6.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2,>=1.6.2->tfx) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2,>=1.6.2->tfx) (2.29.0)\nRequirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (2.7.0)\nRequirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (5.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx) (3.10)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score<2,>=0.1.2->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (3.2.4)\nCollecting portalocker (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (5.3.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.0->tfx) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.0->tfx) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.0->tfx) (3.1.3)\nINFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\nCollecting tf-keras>=2 (from tensorflow-transform<1.17.0,>=1.16.0->tfx)\n  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: keyring in /usr/lib/python3/dist-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx) (23.5.0)\nRequirement already satisfied: pluggy in /usr/local/lib/python3.10/dist-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx) (1.5.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.16->tfx) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.16->tfx) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.16->tfx) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.16->tfx) (2024.2.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib->kubernetes<27,>=10.0.1->tfx) (3.2.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.16->tfx) (2024.2.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.8.4)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (1.2.15)\nRequirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (8.5.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (0.50b0)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.2.13)\nRequirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (6.5.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx) (3.0.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx) (3.21.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx) (0.1.2)\nRequirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (6.3.3)\nRequirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (24.0.1)\nRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (23.1.0)\nRequirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (5.7.2)\nRequirement already satisfied: jupyter-client>=5.3.4 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (8.6.3)\nRequirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (5.10.4)\nRequirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (6.4.5)\nRequirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (1.6.0)\nRequirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (5.5.6)\nRequirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.18.1)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.21.1)\nRequirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (1.1.0)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (4.3.6)\nRequirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.2.4)\nRequirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.3.0)\nRequirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.4)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (6.2.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (1.5.1)\nRequirement already satisfied: testpath in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.6.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (4.12.3)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.5.13)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (2.21.1)\nRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (21.2.0)\nRequirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (2.12.5)\nRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (1.17.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (2.6)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.5.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (2.22)\nRequirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (3.7.1)\nRequirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.12.0)\nRequirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.5.3)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (1.2.2)\nRequirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (3.2.1)\nRequirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (0.1.1)\nRequirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (1.5.1)\nRequirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (3.0.0)\nRequirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (1.3.0)\nRequirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (24.11.1)\nRequirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.48.0,>=0.47.0->tfx) (2.9.0.20241206)\nDownloading tfx-1.16.0-py3-none-any.whl (7.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ml_pipelines_sdk-1.16.0-py3-none-any.whl (7.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading apache_beam-2.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading kubernetes-26.1.0-py2.py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ml_metadata-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0mm\n\u001b[?25hDownloading tensorflow_data_validation-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_model_analysis-0.47.1-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_serving_api-2.16.1-py2.py3-none-any.whl (26 kB)\nDownloading tensorflow_transform-1.16.0-py3-none-any.whl (451 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.5/451.5 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tfx_bsl-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\nDownloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\nDownloading google_cloud_bigquery_storage-2.28.0-py2.py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_cloud_dlp-3.28.0-py2.py3-none-any.whl (210 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.4/210.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_cloud_pubsublite-1.12.0-py2.py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_cloud_recommendations_ai-0.10.16-py2.py3-none-any.whl (209 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_cloud_spanner-3.52.0-py2.py3-none-any.whl (449 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.9/449.9 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ipywidgets-7.8.5-py2.py3-none-any.whl (124 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.1/124.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading objsize-0.7.1-py3-none-any.whl (11 kB)\nDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\nDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\nDownloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\nDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading keyrings.google_artifactregistry_auth-1.1.2-py3-none-any.whl (10 kB)\nDownloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\nDownloading jupyterlab_widgets-1.1.11-py3-none-any.whl (246 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.9/246.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading widgetsnbextension-3.6.10-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: google-apitools, crcmod, dill, hdfs, pyfarmhash, rouge-score, docopt\n  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131014 sha256=67519316eb058174cf76a74618d41dc8a6b2b6a14d6e2b338f15516323ffabd3\n  Stored in directory: /root/.cache/pip/wheels/04/b7/e0/9712f8c23a5da3d9d16fb88216b897bf60e85b12f5470f26ee\n  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31407 sha256=f297909ba79c5da91b807311f29b9f2c766d51ec80ea5d7bc28802642f549edc\n  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=18a253705ece3e51df79b21258081a9f3c9607e2e8a3bebbaadf0c7c0b2a9207\n  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=b90bf5e1bfd54dea5a8588caac576609fd1fa2ba9ccc65065ca4eb39c26ae713\n  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n  Building wheel for pyfarmhash (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp310-cp310-linux_x86_64.whl size=88656 sha256=79aacff913fc82fd10e18aaa126abe0f31c4417c5e1bd23b7a59c3e06418b7ac\n  Stored in directory: /root/.cache/pip/wheels/e0/08/da/f66b1f3258fe3f1e767b2136c5444dbfa9fa3f7944cc5e1983\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=8feaef572273f7751a64d16624dc8cca77fd2eb3e76622d5e8d1bc596bd32f78\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=f3ff725e67de9bf3df86ed54485507497b239c8dfa132ed9c3130b7eb01f631d\n  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\nSuccessfully built google-apitools crcmod dill hdfs pyfarmhash rouge-score docopt\nInstalling collected packages: pyfarmhash, docopt, crcmod, zstandard, uritemplate, tensorflow-metadata, tensorflow-estimator, redis, pydot, pyarrow-hotfix, portalocker, objsize, jupyterlab-widgets, jsonpickle, grpcio, fasteners, fastavro, dill, cloudpickle, attrs, ml-metadata, hdfs, grpc-interceptor, kubernetes, keyrings.google-artifactregistry-auth, google-apitools, google-api-core, google-api-python-client, ml-pipelines-sdk, google-cloud-storage, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-dlp, google-cloud-bigquery-storage, google-cloud-pubsublite, widgetsnbextension, ipywidgets, ml-dtypes, tensorboard, pyarrow, tensorflow, apache-beam, tensorflow-serving-api, pandas, tfx-bsl, tf-keras, scipy, sacrebleu, rouge-score, tensorflow-transform, tensorflow-model-analysis, tensorflow-hub, tensorflow-data-validation, scikit-learn, tfx\n  Attempting uninstall: uritemplate\n    Found existing installation: uritemplate 4.1.1\n    Uninstalling uritemplate-4.1.1:\n      Successfully uninstalled uritemplate-4.1.1\n  Attempting uninstall: tensorflow-metadata\n    Found existing installation: tensorflow-metadata 1.13.1\n    Uninstalling tensorflow-metadata-1.13.1:\n      Successfully uninstalled tensorflow-metadata-1.13.1\n  Attempting uninstall: pydot\n    Found existing installation: pydot 3.0.3\n    Uninstalling pydot-3.0.3:\n      Successfully uninstalled pydot-3.0.3\n  Attempting uninstall: jupyterlab-widgets\n    Found existing installation: jupyterlab_widgets 3.0.13\n    Uninstalling jupyterlab_widgets-3.0.13:\n      Successfully uninstalled jupyterlab_widgets-3.0.13\n  Attempting uninstall: jsonpickle\n    Found existing installation: jsonpickle 4.0.1\n    Uninstalling jsonpickle-4.0.1:\n      Successfully uninstalled jsonpickle-4.0.1\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.68.1\n    Uninstalling grpcio-1.68.1:\n      Successfully uninstalled grpcio-1.68.1\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: cloudpickle\n    Found existing installation: cloudpickle 3.1.0\n    Uninstalling cloudpickle-3.1.0:\n      Successfully uninstalled cloudpickle-3.1.0\n  Attempting uninstall: attrs\n    Found existing installation: attrs 25.1.0\n    Uninstalling attrs-25.1.0:\n      Successfully uninstalled attrs-25.1.0\n  Attempting uninstall: google-api-core\n    Found existing installation: google-api-core 1.34.1\n    Uninstalling google-api-core-1.34.1:\n      Successfully uninstalled google-api-core-1.34.1\n  Attempting uninstall: google-api-python-client\n    Found existing installation: google-api-python-client 2.155.0\n    Uninstalling google-api-python-client-2.155.0:\n      Successfully uninstalled google-api-python-client-2.155.0\n  Attempting uninstall: google-cloud-storage\n    Found existing installation: google-cloud-storage 2.14.0\n    Uninstalling google-cloud-storage-2.14.0:\n      Successfully uninstalled google-cloud-storage-2.14.0\n  Attempting uninstall: widgetsnbextension\n    Found existing installation: widgetsnbextension 4.0.13\n    Uninstalling widgetsnbextension-4.0.13:\n      Successfully uninstalled widgetsnbextension-4.0.13\n  Attempting uninstall: ipywidgets\n    Found existing installation: ipywidgets 8.1.5\n    Uninstalling ipywidgets-8.1.5:\n      Successfully uninstalled ipywidgets-8.1.5\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.17.1\n    Uninstalling tensorboard-2.17.1:\n      Successfully uninstalled tensorboard-2.17.1\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.17.1\n    Uninstalling tensorflow-2.17.1:\n      Successfully uninstalled tensorflow-2.17.1\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.3\n    Uninstalling pandas-2.2.3:\n      Successfully uninstalled pandas-2.2.3\n  Attempting uninstall: tf-keras\n    Found existing installation: tf_keras 2.17.0\n    Uninstalling tf_keras-2.17.0:\n      Successfully uninstalled tf_keras-2.17.0\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.13.1\n    Uninstalling scipy-1.13.1:\n      Successfully uninstalled scipy-1.13.1\n  Attempting uninstall: tensorflow-hub\n    Found existing installation: tensorflow-hub 0.16.1\n    Uninstalling tensorflow-hub-0.16.1:\n      Successfully uninstalled tensorflow-hub-0.16.1\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.1 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\ncudf-cu12 25.2.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ncudf-cu12 25.2.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 10.0.1 which is incompatible.\ndask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\ndask-cudf-cu12 25.2.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\ndask-expr 1.1.21 requires pyarrow>=14.0.1, but you have pyarrow 10.0.1 which is incompatible.\ndatasets 3.3.1 requires pyarrow>=15.0.0, but you have pyarrow 10.0.1 which is incompatible.\ndistributed 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.24.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\nlangchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\nmizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\nmultiprocess 0.70.16 requires dill>=0.3.8, but you have dill 0.3.1.1 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.1.1 which is incompatible.\nplotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\nplotnine 0.14.4 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\npylibcudf-cu12 25.2.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 10.0.1 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.16.2 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tf-keras~=2.17, but you have tf-keras 2.16.0 which is incompatible.\ntensorflow-text 2.17.0 requires tensorflow<2.18,>=2.17.0, but you have tensorflow 2.16.2 which is incompatible.\nvisions 0.7.6 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nxarray 2024.11.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed apache-beam-2.63.0 attrs-23.2.0 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.10.0 fasteners-0.19 google-api-core-2.24.1 google-api-python-client-1.12.11 google-apitools-0.5.31 google-cloud-bigquery-storage-2.28.0 google-cloud-dlp-3.28.0 google-cloud-pubsublite-1.12.0 google-cloud-recommendations-ai-0.10.16 google-cloud-spanner-3.52.0 google-cloud-storage-2.19.0 grpc-interceptor-0.15.4 grpcio-1.65.5 hdfs-2.7.3 ipywidgets-7.8.5 jsonpickle-3.4.2 jupyterlab-widgets-1.1.11 keyrings.google-artifactregistry-auth-1.1.2 kubernetes-26.1.0 ml-dtypes-0.3.2 ml-metadata-1.16.0 ml-pipelines-sdk-1.16.0 objsize-0.7.1 pandas-1.5.3 portalocker-3.1.1 pyarrow-10.0.1 pyarrow-hotfix-0.6 pydot-1.4.2 pyfarmhash-0.3.2 redis-5.2.1 rouge-score-0.1.2 sacrebleu-2.5.1 scikit-learn-1.5.1 scipy-1.12.0 tensorboard-2.16.2 tensorflow-2.16.2 tensorflow-data-validation-1.16.1 tensorflow-estimator-2.15.0 tensorflow-hub-0.15.0 tensorflow-metadata-1.16.1 tensorflow-model-analysis-0.47.1 tensorflow-serving-api-2.16.1 tensorflow-transform-1.16.0 tf-keras-2.16.0 tfx-1.16.0 tfx-bsl-1.16.1 uritemplate-3.0.1 widgetsnbextension-3.6.10 zstandard-0.23.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv(\"/kaggle/input/heart-disease-dataset/heart.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:46:47.185865Z","iopub.execute_input":"2025-02-25T02:46:47.186316Z","iopub.status.idle":"2025-02-25T02:46:47.634203Z","shell.execute_reply.started":"2025-02-25T02:46:47.186265Z","shell.execute_reply":"2025-02-25T02:46:47.633030Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n0   52    1   0       125   212    0        1      168      0      1.0      2   \n1   53    1   0       140   203    1        0      155      1      3.1      0   \n2   70    1   0       145   174    0        1      125      1      2.6      0   \n3   61    1   0       148   203    0        1      161      0      0.0      2   \n4   62    0   0       138   294    1        1      106      0      1.9      1   \n\n   ca  thal  target  \n0   2     3       0  \n1   0     3       0  \n2   0     3       0  \n3   1     3       0  \n4   3     2       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52</td>\n      <td>1</td>\n      <td>0</td>\n      <td>125</td>\n      <td>212</td>\n      <td>0</td>\n      <td>1</td>\n      <td>168</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53</td>\n      <td>1</td>\n      <td>0</td>\n      <td>140</td>\n      <td>203</td>\n      <td>1</td>\n      <td>0</td>\n      <td>155</td>\n      <td>1</td>\n      <td>3.1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>70</td>\n      <td>1</td>\n      <td>0</td>\n      <td>145</td>\n      <td>174</td>\n      <td>0</td>\n      <td>1</td>\n      <td>125</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61</td>\n      <td>1</td>\n      <td>0</td>\n      <td>148</td>\n      <td>203</td>\n      <td>0</td>\n      <td>1</td>\n      <td>161</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>62</td>\n      <td>0</td>\n      <td>0</td>\n      <td>138</td>\n      <td>294</td>\n      <td>1</td>\n      <td>1</td>\n      <td>106</td>\n      <td>0</td>\n      <td>1.9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"_components_script = '''\n\"\"\"Initiate tfx pipeline components\"\"\"\n\nimport os\n\nimport tensorflow_model_analysis as tfma\nfrom tfx.components import (\n    CsvExampleGen,\n    Evaluator,\n    ExampleValidator,\n    Pusher,\n    SchemaGen,\n    StatisticsGen,\n    Trainer,\n    Transform,\n    Tuner,\n)\nfrom tfx.dsl.components.common.resolver import Resolver\nfrom tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import (\n    LatestBlessedModelStrategy,\n)\nfrom tfx.proto import example_gen_pb2, pusher_pb2, trainer_pb2\nfrom tfx.types import Channel\nfrom tfx.types.standard_artifacts import Model, ModelBlessing\n\ndef init_components(args):  # pylint: disable=too-many-locals\n    \"\"\"Initiate tfx pipeline components\n\n    Args:\n        args (dict): args that contain pipeline configuration\n\n    Returns:\n        TFX components\n    \"\"\"\n    output = example_gen_pb2.Output(\n        split_config=example_gen_pb2.SplitConfig(\n            splits=[\n                example_gen_pb2.SplitConfig.Split(name=\"train\", hash_buckets=8),\n                example_gen_pb2.SplitConfig.Split(name=\"eval\", hash_buckets=2),\n            ]\n        )\n    )\n\n    example_gen = CsvExampleGen(input_base=args[\"data_dir\"], output_config=output)\n\n    statistics_gen = StatisticsGen(examples=example_gen.outputs[\"examples\"])\n\n    schema_gen = SchemaGen(statistics=statistics_gen.outputs[\"statistics\"])\n\n    example_validator = ExampleValidator(\n        statistics=statistics_gen.outputs[\"statistics\"],\n        schema=schema_gen.outputs[\"schema\"],\n    )\n\n    transform = Transform(\n        examples=example_gen.outputs[\"examples\"],\n        schema=schema_gen.outputs[\"schema\"],\n        module_file=os.path.abspath(args[\"transform_module\"]),\n    )\n\n    tuner = Tuner(\n        module_file=os.path.abspath(args[\"tuner_module\"]),\n        examples=transform.outputs[\"transformed_examples\"],\n        transform_graph=transform.outputs[\"transform_graph\"],\n        schema=schema_gen.outputs[\"schema\"],\n        train_args=trainer_pb2.TrainArgs(\n            splits=[\"train\"],\n            num_steps=args[\"train_steps\"],\n        ),\n        eval_args=trainer_pb2.EvalArgs(\n            splits=[\"eval\"],\n            num_steps=args[\"eval_steps\"],\n        ),\n    )\n\n    trainer = Trainer(\n        module_file=args[\"trainer_module\"],\n        examples=transform.outputs[\"transformed_examples\"],\n        transform_graph=transform.outputs[\"transform_graph\"],\n        schema=schema_gen.outputs[\"schema\"],\n        hyperparameters=tuner.outputs[\"best_hyperparameters\"],\n        train_args=trainer_pb2.TrainArgs(\n            splits=[\"train\"],\n            num_steps=args[\"train_steps\"],\n        ),\n        eval_args=trainer_pb2.EvalArgs(\n            splits=[\"eval\"],\n            num_steps=args[\"eval_steps\"],\n        ),\n    )\n\n\n    model_resolver = Resolver(\n        strategy_class=LatestBlessedModelStrategy,\n        model=Channel(type=Model),\n        model_blessing=Channel(type=ModelBlessing),\n    ).with_id(\"Latest_blessed_model_resolver\")\n\n    \n    \n    # Konfigurasi metrik evaluasi\n    metrics_specs = [\n        tfma.MetricsSpec(\n            metrics=[\n                tfma.MetricConfig(class_name=\"ExampleCount\"),\n                tfma.MetricConfig(class_name=\"AUC\"),\n                tfma.MetricConfig(class_name=\"FalsePositives\"),\n                tfma.MetricConfig(class_name=\"TruePositives\"),\n                tfma.MetricConfig(class_name=\"FalseNegatives\"),\n                tfma.MetricConfig(class_name=\"TrueNegatives\"),\n                tfma.MetricConfig(\n                    class_name=\"BinaryAccuracy\",\n                    threshold=tfma.MetricThreshold(\n                        value_threshold=tfma.GenericValueThreshold(\n                            lower_bound={\"value\": 0.5}  \n                        ),\n                        change_threshold=tfma.GenericChangeThreshold(\n                            direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n                            absolute={\"value\": 0.0001}, \n                        ),\n                    ),\n                ),\n            ]\n        )\n    ]\n\n    # Konfigurasi evaluasi model dengan baseline\n    eval_config = tfma.EvalConfig(\n        model_specs=[\n            tfma.ModelSpec(label_key=\"target\", signature_name=\"serving_default\"),\n        ],\n        slicing_specs=[\n            tfma.SlicingSpec(),  # Evaluasi secara keseluruhan\n        ],\n        metrics_specs=metrics_specs,\n    )\n    \n    # Evaluator\n    evaluator = Evaluator(\n        examples=example_gen.outputs[\"examples\"],\n        model=trainer.outputs[\"model\"],\n        baseline_model=model_resolver.outputs[\"model\"],\n        eval_config=eval_config,\n    )\n\n\n    pusher = Pusher(\n        model=trainer.outputs[\"model\"],\n        model_blessing=evaluator.outputs[\"blessing\"],\n        push_destination=pusher_pb2.PushDestination(\n            filesystem=pusher_pb2.PushDestination.Filesystem(\n                base_directory=args[\"serving_model_dir\"]\n            )\n        ),\n    )\n\n\n    components = (\n        example_gen,\n        statistics_gen,\n        schema_gen,\n        example_validator,\n        transform,\n        tuner,\n        trainer,\n        model_resolver,\n        evaluator,\n        pusher,\n    )\n\n    return components\n\n'''\n\nwith open(\"components.py\",\"w\") as f:\n    f.write(_components_script)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:46:47.635895Z","iopub.execute_input":"2025-02-25T02:46:47.636375Z","iopub.status.idle":"2025-02-25T02:46:47.643086Z","shell.execute_reply.started":"2025-02-25T02:46:47.636343Z","shell.execute_reply":"2025-02-25T02:46:47.641855Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"_pipeline_script = '''\n\n\"\"\"Pipeline module\"\"\"\n\nfrom typing import Text\n\nfrom absl import logging\nfrom tfx.orchestration import metadata, pipeline\n\n\ndef init_pipeline(\n    pipeline_root: Text, pipeline_name, metadata_path, components\n) -> pipeline.Pipeline:\n    \"\"\"Initiate tfx pipeline\n\n    Args:\n        pipeline_root (Text): path to pipeline directory\n        pipeline_name (str): pipeline name\n        metadata_path (str): path to metadata directory\n        components (dict): tfx components\n\n    Returns:\n        pipeline.Pipeline: pipeline orchestration\n    \"\"\"\n    logging.set_verbosity(logging.INFO)\n\n    beam_args = [\n        \"--direct_running_mode=multi_processing\",\n        \"----direct_num_workers=0\",\n    ]\n\n    return pipeline.Pipeline(\n        pipeline_name=pipeline_name,\n        pipeline_root=pipeline_root,\n        components=components,\n        enable_cache=True,\n        metadata_connection_config=metadata.sqlite_metadata_connection_config(\n            metadata_path,\n        ),\n        beam_pipeline_args=beam_args,\n    )\n\n'''\n\nwith open (\"pipeline.py\", \"w\") as f:\n    f.write(_pipeline_script)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:46:47.644397Z","iopub.execute_input":"2025-02-25T02:46:47.644724Z","iopub.status.idle":"2025-02-25T02:46:47.668442Z","shell.execute_reply.started":"2025-02-25T02:46:47.644699Z","shell.execute_reply":"2025-02-25T02:46:47.667170Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"_transform_script = '''\n\n\"\"\"Transform module\"\"\"\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\n\nCATEGORICAL_FEATURES = {\n    \"sex\": 2,\n    \"cp\": 4,\n    \"fbs\": 2,\n    \"restecg\": 3,\n    \"exang\": 2,\n    \"slope\": 3,\n    \"ca\": 4,  # Bisa bernilai 0-3, jadi ada 4 kategori\n    \"thal\": 3, # Bisa bernilai 0-2, jadi ada 3 kategori\n}\n\nNUMERICAL_FEATURES = [\n    \"age\",\n    \"trestbps\",\n    \"chol\",\n    \"thalach\",\n    \"oldpeak\",\n]\n\nLABEL_KEY = \"target\"\n\n\ndef transformed_name(key):\n    \"\"\"Renaming transformed features\"\"\"\n    return key + \"_xf\"\n\n\ndef convert_num_to_one_hot(label_tensor, num_labels=2):\n    \"\"\"\n    Convert a label (0 or 1) into a one-hot vector\n    Args:\n        int: label_tensor (0 or 1)\n    Returns\n        label tensor\n    \"\"\"\n    one_hot_tensor = tf.one_hot(label_tensor, num_labels)\n    return tf.reshape(one_hot_tensor, [-1, num_labels])\n\n\ndef preprocessing_fn(inputs):\n    \"\"\"\n    Preprocess input features into transformed features\n\n    Args:\n        inputs: map from feature keys to raw features.\n\n    Return:\n        outputs: map from feature keys to transformed features.\n    \"\"\"\n\n    outputs = {}\n\n    for key in CATEGORICAL_FEATURES:  # pylint: disable=consider-using-dict-items\n        dim = CATEGORICAL_FEATURES[key]\n        int_value = tft.compute_and_apply_vocabulary(inputs[key], top_k=dim + 1)\n        outputs[transformed_name(key)] = convert_num_to_one_hot(\n            int_value, num_labels=dim + 1\n        )\n\n    for feature in NUMERICAL_FEATURES:\n        outputs[transformed_name(feature)] = tft.scale_to_0_1(inputs[feature])\n\n    outputs[transformed_name(LABEL_KEY)] = tf.cast(inputs[LABEL_KEY], tf.int64)\n\n    return outputs\n\n'''\n\nwith open(\"transform.py\",\"w\") as f:\n    f.write(_transform_script)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:46:47.669961Z","iopub.execute_input":"2025-02-25T02:46:47.670358Z","iopub.status.idle":"2025-02-25T02:46:47.691580Z","shell.execute_reply.started":"2025-02-25T02:46:47.670287Z","shell.execute_reply":"2025-02-25T02:46:47.690580Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"_tuner_script = '''\n\"\"\"Tuner module\"\"\"\n\nfrom typing import Any, Dict, NamedTuple, Text\n\nimport keras_tuner as kt\nimport tensorflow as tf\nimport tensorflow_transform as tft\nfrom keras import layers\nfrom keras_tuner.engine import base_tuner\nimport sys\nsys.path.append(\"/kaggle/working/\")\nimport transform,tuner\n\n\n\nfrom transform import (\n    CATEGORICAL_FEATURES,\n    LABEL_KEY,\n    NUMERICAL_FEATURES,\n    transformed_name,\n)\n\nNUM_EPOCHS = 5\n\nTunerFnResult = NamedTuple(\n    \"TunerFnResult\",\n    [\n        (\"tuner\", base_tuner.BaseTuner),\n        (\"fit_kwargs\", Dict[Text, Any]),\n    ],\n)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_binary_accuracy\",\n    mode=\"max\",\n    verbose=1,\n    patience=10,\n    restore_best_weights=True,\n)\n\n\ndef gzip_reader_fn(filenames):\n    \"\"\"Loads compression data\n\n    Args:\n        filenames (str): a path to the data directory\n\n    Returns:\n        TfRecord: Compressed data\n    \"\"\"\n\n    return tf.data.TFRecordDataset(filenames, compression_type=\"GZIP\")\n\n\ndef input_fn(file_pattern, tf_transform_output, batch_size=64):\n    \"\"\"Generated features and labels for tuning/training\n\n    Args:\n        file_pattern: input tf_record file pattern\n        tf_transform_output: a TFTransformOutput\n        batch_size: representing the number of consecutive elements of\n        returned dataset to combine in a single batch. Defaults to 64.\n\n    Returns:\n        a dataset that contains (featurs, indices) tuple where features\n        is a dictionary of Tensors, and indices is a single Tensor of\n        label indices\n    \"\"\"\n\n    transform_feature_spec = tf_transform_output.transformed_feature_spec().copy()\n\n    dataset = tf.data.experimental.make_batched_features_dataset(\n        file_pattern=file_pattern,\n        batch_size=batch_size,\n        features=transform_feature_spec,\n        reader=gzip_reader_fn,\n        label_key=transformed_name(LABEL_KEY),\n    )\n\n    return dataset\n\n\ndef get_model_tuner(hp):\n    \"\"\"This function defines a hyperparameters to tune for keras Model\n\n    Args:\n        hp (kt.HyperParameters): object to setting hyperparameters\n\n    Returns:\n        tf.keras.Model: Keras model object\n    \"\"\"\n\n    n_layers = hp.Int(\"n_layers\", min_value=1, max_value=5, step=1)\n    dense_units = hp.Int(\n        \"dense_units\",\n        min_value=16,\n        max_value=128,\n        step=32,\n    )\n    lr = hp.Choice(\"lr\", values=[1e-2, 1e-3, 1e-4])\n\n    input_features = []\n\n    for key, dim in CATEGORICAL_FEATURES.items():\n        input_features.append(\n            layers.Input(shape=(dim + 1,), name=transformed_name(key))\n        )\n\n    for feature in NUMERICAL_FEATURES:\n        input_features.append(layers.Input(shape=(1,), name=transformed_name(feature)))\n\n    concatenate = layers.concatenate(input_features)\n    x = layers.Dense(dense_units, activation=tf.nn.relu)(concatenate)\n\n    for _ in range(n_layers):\n        x = layers.Dense(dense_units, activation=tf.nn.relu)(x)\n\n    x = layers.Dropout(0.25)(x)\n\n    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n\n    model = tf.keras.Model(inputs=input_features, outputs=outputs)\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n        loss=tf.keras.losses.BinaryCrossentropy(),\n        metrics=[\"binary_accuracy\"],\n    )\n\n    model.summary()\n\n    return model\n\n\ndef tuner_fn(fn_args):\n    \"\"\"Tune the model to get the best hyperparameters\n\n    Args:\n        fn_args (FnArgs): Holds args used to train the model as name/value pair\n\n    Returns:\n        TunerFnResult (NamedTuple): object to run model tuner\n    \"\"\"\n\n    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n\n    train_set = input_fn(fn_args.train_files[0], tf_transform_output)\n    eval_set = input_fn(fn_args.eval_files[0], tf_transform_output)\n\n    tuner = kt.Hyperband(\n        hypermodel=get_model_tuner,\n        objective=kt.Objective(\"binary_accuracy\", direction=\"max\"),\n        max_epochs=NUM_EPOCHS,\n        factor=3,\n        directory=fn_args.working_dir,\n        project_name=\"kt_hyperband\",\n    )\n    # Pastikan max_trials memiliki nilai default jika None\n    if tuner.oracle.max_trials is None:\n        tuner.oracle.max_trials = 10  # Atur nilai default sesuai kebutuhan\n\n\n    return TunerFnResult(\n        tuner=tuner,\n        fit_kwargs={\n            \"x\": train_set,\n            \"validation_data\": eval_set,\n            \"steps_per_epoch\": fn_args.train_steps,\n            \"validation_steps\": fn_args.eval_steps,\n            \"callbacks\": [early_stop],\n        },\n    )\n'''\n\nwith open(\"tuner.py\", 'w') as f:\n    f.write(_tuner_script)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:46:47.692627Z","iopub.execute_input":"2025-02-25T02:46:47.692992Z","iopub.status.idle":"2025-02-25T02:46:47.714994Z","shell.execute_reply.started":"2025-02-25T02:46:47.692955Z","shell.execute_reply":"2025-02-25T02:46:47.713645Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"_trainer_script = '''\n\n\"\"\"Training module\"\"\"\n\nimport os\n\nimport tensorflow as tf\nimport tensorflow_transform as tft\nfrom tensorflow.keras.utils import plot_model\nimport sys\nsys.path.append(\"/kaggle/working/\")\nimport transform,tuner\n\nfrom transform import (\n    CATEGORICAL_FEATURES,\n    LABEL_KEY,\n    NUMERICAL_FEATURES,\n    transformed_name,\n)\nfrom tuner import early_stop, gzip_reader_fn\n\n\ndef get_model(hp):\n    \"\"\"This function defines a keras Model with the best hyperparameters from tuning\n\n    Args:\n        hp (kt.HyperParameters): object that contains hyperparameters tuning configuration\n\n    Returns:\n        tf.keras.Model: model as a Keras object\n    \"\"\"\n\n    # one-hot categorical features\n    input_features = []\n    for key, dim in CATEGORICAL_FEATURES.items():\n        input_features.append(\n            tf.keras.Input(shape=(dim + 1,), name=transformed_name(key))\n        )\n\n    for feature in NUMERICAL_FEATURES:\n        input_features.append(\n            tf.keras.Input(shape=(1,), name=transformed_name(feature))\n        )\n\n    concatenate = tf.keras.layers.concatenate(input_features)\n    x = tf.keras.layers.Dense(hp.get(\"dense_units\"), activation=tf.nn.relu)(concatenate)\n\n    for _ in range(hp.get(\"n_layers\")):\n        x = tf.keras.layers.Dense(hp.get(\"dense_units\"), activation=\"relu\")(x)\n\n    x = tf.keras.layers.Dropout(0.25)(x)\n    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n\n    model = tf.keras.models.Model(inputs=input_features, outputs=outputs)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=hp.get(\"lr\")),\n        loss=\"binary_crossentropy\",\n        metrics=[tf.keras.metrics.BinaryAccuracy()],\n    )\n\n    model.summary()\n\n    return model\n\n\ndef get_serve_tf_examples_fn(model, tf_transform_output):\n    \"\"\"Returns a function that parses a serialized tf.Example.\"\"\"\n\n    model.tft_layer = tf_transform_output.transform_features_layer()\n\n    @tf.function\n    def serve_tf_examples_fn(serialized_tf_examples):\n        \"\"\"Returns the output to be used in the serving signature.\"\"\"\n        feature_spec = tf_transform_output.raw_feature_spec()\n        feature_spec.pop(LABEL_KEY)\n        parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n\n        transformed_features = model.tft_layer(parsed_features)\n\n        outputs = model(transformed_features)\n        return {\"outputs\": outputs}\n\n    return serve_tf_examples_fn\n\n\ndef input_fn(file_pattern, tf_transform_output, batch_size=64):\n    \"\"\"Generates features and labels for tuning/training.\n    Args:\n        file_pattern: input tfrecord file pattern.\n        tf_transform_output: A TFTransformOutput.\n        batch_size: representing the number of consecutive elements of\n        returned dataset to combine in a single batch\n    Returns:\n        A dataset that contains (features, indices) tuple where features\n        is a dictionary of Tensors, and indices is a single Tensor of\n        label indices.\n    \"\"\"\n    transformed_feature_spec = tf_transform_output.transformed_feature_spec().copy()\n\n    dataset = tf.data.experimental.make_batched_features_dataset(\n        file_pattern=file_pattern,\n        batch_size=batch_size,\n        features=transformed_feature_spec,\n        reader=gzip_reader_fn,\n        label_key=transformed_name(LABEL_KEY),\n    )\n\n    return dataset\n\n\n# TFX Trainer will call this function.\ndef run_fn(fn_args):\n    \"\"\"Train the model based on given args.\n    Args:\n    fn_args: Holds args used to train the model as name/value pairs.\n    \"\"\"\n    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n    hp = fn_args.hyperparameters[\"values\"]\n\n    train_dataset = input_fn(fn_args.train_files, tf_transform_output, 64)\n    eval_dataset = input_fn(fn_args.eval_files, tf_transform_output, 64)\n\n    model = get_model(hp)\n\n    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), \"logs\")\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n        log_dir=log_dir, update_freq=\"batch\"\n    )\n\n    mc = tf.keras.callbacks.ModelCheckpoint(\n        os.path.join(fn_args.serving_model_dir, \"model.keras\"),\n        monitor=\"val_binary_accuracy\",\n        mode=\"max\",\n        verbose=1,\n        save_best_only=True,\n    )\n\n    # Train the model\n    model.fit(\n        x=train_dataset,\n        validation_data=eval_dataset,\n        callbacks=[tensorboard_callback, early_stop, mc],\n        steps_per_epoch=fn_args.train_steps,\n        validation_steps=fn_args.eval_steps,\n        epochs=hp.get(\"tuner/epochs\"),\n    )\n\n    signatures = {\n        \"serving_default\": get_serve_tf_examples_fn(\n            model, tf_transform_output\n        ).get_concrete_function(\n            tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\")\n        ),\n    }\n    tf.saved_model.save(model, fn_args.serving_model_dir, signatures=signatures)\n\n    plot_model(\n        model, to_file=\"/kaggle/working/model_plot.png\", show_shapes=True, show_layer_names=True\n    )\n'''\n\nwith open(\"train.py\",\"w\") as f:\n    f.write(_trainer_script)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:46:47.716221Z","iopub.execute_input":"2025-02-25T02:46:47.716559Z","iopub.status.idle":"2025-02-25T02:46:47.735151Z","shell.execute_reply.started":"2025-02-25T02:46:47.716531Z","shell.execute_reply":"2025-02-25T02:46:47.734143Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/\")\nimport pipeline\n\nimport components as components_module","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:46:47.738033Z","iopub.execute_input":"2025-02-25T02:46:47.738399Z","iopub.status.idle":"2025-02-25T02:47:40.651131Z","shell.execute_reply.started":"2025-02-25T02:46:47.738362Z","shell.execute_reply":"2025-02-25T02:47:40.650160Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import os\nfrom tfx.orchestration.beam.beam_dag_runner import BeamDagRunner","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:47:40.652410Z","iopub.execute_input":"2025-02-25T02:47:40.652781Z","iopub.status.idle":"2025-02-25T02:47:40.739330Z","shell.execute_reply.started":"2025-02-25T02:47:40.652736Z","shell.execute_reply":"2025-02-25T02:47:40.738465Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"PIPELANE_NAME = \"jabir_muktabir-pipeline\"\n\n# Pipeline inputs\nDATA_ROOT = \"/kaggle/input/heart-disease-dataset\"\nTRANSFORM_MODULE_FILE = \"/kaggle/working/transform.py\"\nTUNER_MODULE_FILE = \"/kaggle/working/tuner.py\"\nTRAINER_MODULE_FILE = \"/kaggle/working/train.py\"\n\n# Pipeline outputs\nOUTPUT_BASE = \"outputs\"\n\nserving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\npipeline_root = os.path.join(OUTPUT_BASE, PIPELANE_NAME)\nmetadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:47:40.740323Z","iopub.execute_input":"2025-02-25T02:47:40.741019Z","iopub.status.idle":"2025-02-25T02:47:40.745963Z","shell.execute_reply.started":"2025-02-25T02:47:40.740982Z","shell.execute_reply":"2025-02-25T02:47:40.744919Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"components_args = {\n    \"data_dir\": DATA_ROOT,\n    \"trainer_module\": TRAINER_MODULE_FILE,\n    \"tuner_module\": TUNER_MODULE_FILE,\n    \"transform_module\": TRANSFORM_MODULE_FILE,\n    \"train_steps\": 20,\n    \"eval_steps\": 10,\n    \"serving_model_dir\": serving_model_dir,\n}\n\npipeline_components = components_module.init_components(components_args)\n\npipeline = pipeline.init_pipeline(\n    pipeline_root, PIPELANE_NAME, metadata_path, pipeline_components\n)\nBeamDagRunner().run(pipeline)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:47:40.746983Z","iopub.execute_input":"2025-02-25T02:47:40.747410Z","iopub.status.idle":"2025-02-25T02:51:12.457711Z","shell.execute_reply.started":"2025-02-25T02:47:40.747374Z","shell.execute_reply":"2025-02-25T02:51:12.456517Z"}},"outputs":[{"name":"stdout","text":"Trial 10 Complete [00h 00m 04s]\nbinary_accuracy: 0.6499999761581421\n\nBest binary_accuracy So Far: 0.9546874761581421\nTotal elapsed time: 00h 00m 36s\nResults summary\nResults in outputs/jabir_muktabir-pipeline/Tuner/.system/executor_execution/7/.temp/7/kt_hyperband\nShowing 10 best trials\nObjective(name=\"binary_accuracy\", direction=\"max\")\n\nTrial 05 summary\nHyperparameters:\nn_layers: 1\ndense_units: 112\nlr: 0.01\ntuner/epochs: 5\ntuner/initial_epoch: 2\ntuner/bracket: 1\ntuner/round: 1\ntuner/trial_id: 04\nScore: 0.9546874761581421\n\nTrial 06 summary\nHyperparameters:\nn_layers: 5\ndense_units: 112\nlr: 0.01\ntuner/epochs: 5\ntuner/initial_epoch: 2\ntuner/bracket: 1\ntuner/round: 1\ntuner/trial_id: 03\nScore: 0.9429687261581421\n\nTrial 08 summary\nHyperparameters:\nn_layers: 1\ndense_units: 16\nlr: 0.01\ntuner/epochs: 5\ntuner/initial_epoch: 0\ntuner/bracket: 0\ntuner/round: 0\nScore: 0.90234375\n\nTrial 04 summary\nHyperparameters:\nn_layers: 1\ndense_units: 112\nlr: 0.01\ntuner/epochs: 2\ntuner/initial_epoch: 0\ntuner/bracket: 1\ntuner/round: 0\nScore: 0.897656261920929\n\nTrial 03 summary\nHyperparameters:\nn_layers: 5\ndense_units: 112\nlr: 0.01\ntuner/epochs: 2\ntuner/initial_epoch: 0\ntuner/bracket: 1\ntuner/round: 0\nScore: 0.89453125\n\nTrial 02 summary\nHyperparameters:\nn_layers: 5\ndense_units: 112\nlr: 0.001\ntuner/epochs: 2\ntuner/initial_epoch: 0\ntuner/bracket: 1\ntuner/round: 0\nScore: 0.8687499761581421\n\nTrial 07 summary\nHyperparameters:\nn_layers: 4\ndense_units: 16\nlr: 0.001\ntuner/epochs: 5\ntuner/initial_epoch: 0\ntuner/bracket: 0\ntuner/round: 0\nScore: 0.8609374761581421\n\nTrial 01 summary\nHyperparameters:\nn_layers: 2\ndense_units: 48\nlr: 0.001\ntuner/epochs: 2\ntuner/initial_epoch: 0\ntuner/bracket: 1\ntuner/round: 0\nScore: 0.835156261920929\n\nTrial 09 summary\nHyperparameters:\nn_layers: 5\ndense_units: 16\nlr: 0.0001\ntuner/epochs: 5\ntuner/initial_epoch: 0\ntuner/bracket: 0\ntuner/round: 0\nScore: 0.6499999761581421\n\nTrial 00 summary\nHyperparameters:\nn_layers: 5\ndense_units: 16\nlr: 0.001\ntuner/epochs: 2\ntuner/initial_epoch: 0\ntuner/bracket: 1\ntuner/round: 0\nScore: 0.6351562738418579\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ sex_xf (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cp_xf (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ fbs_xf (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ restecg_xf (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ exang_xf (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ slope_xf (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ ca_xf (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ thal_xf (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ age_xf (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ trestbps_xf (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ chol_xf (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ thalach_xf (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ oldpeak_xf (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ sex_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ cp_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n│                           │                        │                │ fbs_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│                           │                        │                │ restecg_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n│                           │                        │                │ exang_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│                           │                        │                │ slope_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│                           │                        │                │ ca_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n│                           │                        │                │ thal_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n│                           │                        │                │ age_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│                           │                        │                │ trestbps_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                           │                        │                │ chol_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n│                           │                        │                │ thalach_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n│                           │                        │                │ oldpeak_xf[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │          \u001b[38;5;34m4,144\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │         \u001b[38;5;34m12,656\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m113\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ sex_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cp_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ fbs_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ restecg_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ exang_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ slope_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ ca_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ thal_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ age_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ trestbps_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ chol_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ thalach_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ oldpeak_xf (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sex_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ cp_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n│                           │                        │                │ fbs_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│                           │                        │                │ restecg_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n│                           │                        │                │ exang_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│                           │                        │                │ slope_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│                           │                        │                │ ca_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n│                           │                        │                │ thal_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n│                           │                        │                │ age_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│                           │                        │                │ trestbps_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                           │                        │                │ chol_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n│                           │                        │                │ thalach_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n│                           │                        │                │ oldpeak_xf[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,144</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,656</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,913\u001b[0m (66.07 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,913</span> (66.07 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,913\u001b[0m (66.07 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,913</span> (66.07 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.7677 - loss: 0.4981\nEpoch 1: val_binary_accuracy improved from -inf to 0.84375, saving model to outputs/jabir_muktabir-pipeline/Trainer/model/8/Format-Serving/model.keras\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 0.7886 - loss: 0.4639 - val_binary_accuracy: 0.8438 - val_loss: 0.3420\nEpoch 2/5\n\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8889 - loss: 0.3399\nEpoch 2: val_binary_accuracy did not improve from 0.84375\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.8938 - loss: 0.3196 - val_binary_accuracy: 0.8266 - val_loss: 0.3806\nEpoch 3/5\n\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9200 - loss: 0.2186\nEpoch 3: val_binary_accuracy did not improve from 0.84375\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9206 - loss: 0.2150 - val_binary_accuracy: 0.8375 - val_loss: 0.3658\nEpoch 4/5\n\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9347 - loss: 0.1679\nEpoch 4: val_binary_accuracy improved from 0.84375 to 0.87031, saving model to outputs/jabir_muktabir-pipeline/Trainer/model/8/Format-Serving/model.keras\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9351 - loss: 0.1674 - val_binary_accuracy: 0.8703 - val_loss: 0.3743\nEpoch 5/5\n\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9432 - loss: 0.1295\nEpoch 5: val_binary_accuracy did not improve from 0.87031\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9469 - loss: 0.1228 - val_binary_accuracy: 0.8250 - val_loss: 0.5859\nRestoring model weights from the end of the best epoch: 4.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import shutil\nshutil.make_archive('/kaggle/working/pipeline', 'zip', '/kaggle/working/outputs')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:51:12.458917Z","iopub.execute_input":"2025-02-25T02:51:12.459281Z","iopub.status.idle":"2025-02-25T02:51:12.586629Z","shell.execute_reply.started":"2025-02-25T02:51:12.459243Z","shell.execute_reply":"2025-02-25T02:51:12.585603Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/pipeline.zip'"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import shutil\nshutil.make_archive('/kaggle/working/serving_model', 'zip', '/kaggle/working/outputs/serving_model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T02:52:37.934915Z","iopub.execute_input":"2025-02-25T02:52:37.935395Z","iopub.status.idle":"2025-02-25T02:52:37.973505Z","shell.execute_reply.started":"2025-02-25T02:52:37.935351Z","shell.execute_reply":"2025-02-25T02:52:37.972354Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/serving_model.zip'"},"metadata":{}}],"execution_count":13}]}